
"""
You couldn't, for example, use the very popular `bert-base-uncased` tokenizer,
even though it's a popular choice for text generation tasks that were trained
on the English Wikipedia and the BookCorpus datasets (which are both available
in the `hf.datasets` library).
""";